{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf3cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a009255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['red', 'green', 'blue', 'orange', 'purple']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351dd9ff",
   "metadata": {},
   "source": [
    "#### HPO Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b2461f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_sequence = {\n",
    "        'MiniGrid-Empty-5x5-v0': 5,\n",
    "        'MiniGrid-DoorKey-5x5-v0': 8, \n",
    "        'MiniGrid-Unlock-v0': 18, \n",
    "        # 'MiniGrid-KeyCorridorS3R1-v0': 12,\n",
    "        # 'MiniGrid-LavaGapS5-v0': 15\n",
    "    }  \n",
    "\n",
    "best_trial = 1\n",
    "study_name = 'mlp_hpo'\n",
    "hpo_path = fr\"C:\\Users\\Logan\\Documents\\School\\Wales\\MSc\\continual-rl-lnn\\src\\continual\\minigrid\\HPO\\{study_name}\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09fd3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all best_trial trials into array\n",
    "seeds = [1001, 2002, 3003] # HPO Seeds\n",
    "perf_mats = [np.load(f'{hpo_path}\\hpo_trial_{best_trial}_{seeds[i]}\\performance_matrix.npy') for i in range(len(seeds))]\n",
    "perf_std_mats = [np.load(f'{hpo_path}\\hpo_trial_{best_trial}_{seeds[i]}\\performance_std_matrix.npy') for i in range(len(seeds))]\n",
    "\n",
    "optuna_mean_perf_mat = np.mean(perf_mats, axis=0) # Per-task average across all perf_matrices\n",
    "optuna_mean_perf_std_mat = np.mean(perf_std_mats, axis=0) # Per-task average across all perf_std_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c6a0c",
   "metadata": {},
   "source": [
    "#### Experiments Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8cc627d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_sequence = {\n",
    "        'MiniGrid-Empty-5x5-v0': 5,\n",
    "        'MiniGrid-DoorKey-5x5-v0': 8, \n",
    "        'MiniGrid-Unlock-v0': 18, \n",
    "        'MiniGrid-LavaGap-v0': 15\n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0da8e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'CfC_A&C'\n",
    "# model_type = 'CfC_Actor'\n",
    "# model_type = 'CfC_Critic'\n",
    "# model_type = 'LSTM'\n",
    "model_type = 'MLP'\n",
    "experiment_name = 'clear_testing'\n",
    "exp_path = fr\"C:\\Users\\Logan\\Documents\\School\\Wales\\MSc\\continual-rl-lnn\\src\\continual\\minigrid\\experiments\\{experiment_name}\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3f900cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_model_dirs(base_path, model_type):\n",
    "    base = Path(base_path)\n",
    "    return [p for p in base.iterdir() if p.is_dir() and model_type in p.name]\n",
    "\n",
    "folders = find_model_dirs(exp_path, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "53aed8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_mats = [np.load(f'{exp_path}\\{f.name}\\performance_matrix.npy') for f in folders]\n",
    "perf_std_mats = [np.load(f'{exp_path}\\{f.name}\\performance_std_matrix.npy') for f in folders]\n",
    "\n",
    "mean_perf_mat = np.mean(perf_mats, axis=0) # Per-task average across all perf_matrices\n",
    "mean_perf_std_mat = np.mean(perf_std_mats, axis=0) # Per-task average across all perf_std_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e88e2207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95500004, 0.        , 0.        ],\n",
       "       [0.95500004, 0.96176797, 0.        ],\n",
       "       [0.95500004, 0.67386397, 0.80937498]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_perf_mat\n",
    "# mean_perf_std_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ff221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perf_matrix(mean_perf_mat, mean_perf_std_mat, sequence=None, save_path='./performance_matrix', std=False):\n",
    "    \n",
    "    # Extract the environment name alone, not 'MiniGrid' or 'v-0' for clean presentation\n",
    "    labels = []\n",
    "    for e in sequence:\n",
    "        e = e.split('-')\n",
    "\n",
    "        # If len(e) is >= 4, the environment has something like '5x5'or '6x6' which is relevant, and should be kept (e.g. Empty-5x5)\n",
    "        if len(e) >= 4:\n",
    "            labels.append('-'.join(e[1:2]))\n",
    "        # Otherwise just take the environment name (e.g. DoorKey)\n",
    "        else:\n",
    "            labels.append(e[1])\n",
    "\n",
    "    if std:\n",
    "        annot = np.empty_like(mean_perf_mat, dtype=object)\n",
    "        for i in range(mean_perf_mat.shape[0]):\n",
    "            for j in range(mean_perf_mat.shape[1]):\n",
    "                annot[i, j] = f\"{mean_perf_mat[i, j]:.2f}\\n±{mean_perf_std_mat[i, j]:.2f}\"\n",
    "\n",
    "    # Reverse the sequence and convert to list to display as the y_tick labels\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    if std:\n",
    "        sns.heatmap(mean_perf_mat, annot=annot, fmt='', cmap='GnBu', xticklabels=labels, yticklabels=labels)\n",
    "    else:\n",
    "        sns.heatmap(mean_perf_mat, annot=True, fmt='.2f', cmap='GnBu', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title('Performance Matrix')\n",
    "    plt.xlabel('Evaluation Task')\n",
    "    plt.ylabel('Train Task')\n",
    "    plt.tight_layout()\n",
    "    if std:\n",
    "        save_path = f'{save_path}_std'\n",
    "\n",
    "    out_path = Path(f\"{save_path}.svg\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "plot_perf_matrix(optuna_mean_perf_mat, optuna_mean_perf_std_mat, hpo_sequence, save_path=f'optuna_{study_name}/mean_performance')\n",
    "plot_perf_matrix(optuna_mean_perf_mat, optuna_mean_perf_std_mat, hpo_sequence, save_path=f'optuna_{study_name}/mean_performance', std=True)\n",
    "# plot_perf_matrix(mean_perf_mat, mean_perf_std_mat, exp_sequence, save_path=f'{model_type}_{experiment_name}/mean_performance')\n",
    "# plot_perf_matrix(mean_perf_mat, mean_perf_std_mat, exp_sequence, save_path=f'{model_type}_{experiment_name}/mean_performance', std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "42276eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_task_names(sequence):\n",
    "#     return [tasks.split('-')[1] for tasks in sequence]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "236969f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_reward(path, sequence, save_path='./loss'):\n",
    "\n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'updates.csv' file\n",
    "#     df = pd.read_csv(f'{path}/episodes.csv')\n",
    "    \n",
    "#     # Extract the timestep\n",
    "#     training_step = df['global_step'][0] # Extract the first logged global_step\n",
    "\n",
    "#     # Extract the first global_step value at the start of every task -> Very messy, but good enough for now\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "\n",
    "#     print(training_step)\n",
    "#     print(task_boundaries_steps)\n",
    "\n",
    "#     # Extract and plot x & y coordinates\n",
    "#     x, y = df['global_step'], df['episodic_return']\n",
    "#     plt.plot(x, y)\n",
    "#     plt.xlabel('Total Timesteps')\n",
    "#     plt.ylabel('Reward')\n",
    "    \n",
    "#     # Add vertical lines across the plot to differentiate task training\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         plt.axvline(x=task_boundaries_steps[indx], color=colours[indx-1], linestyle='dashed', alpha=0.4, label=f'{sequence[indx-1]}→{task}')\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.plot()\n",
    "#     plt.savefig(save_path)\n",
    "#     plt.close()\n",
    "\n",
    "# # plot_reward(path, list(sequence.keys()), './rewards.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2eaeae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_reward(path, sequence, save_path='./rewards.svg'):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "#     import pandas as pd\n",
    "#     from scipy.signal import savgol_filter\n",
    "    \n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'episodes.csv' file\n",
    "#     df = pd.read_csv(f'{path}/episodes.csv')\n",
    "    \n",
    "#     # Set up modern styling\n",
    "#     plt.style.use('fivethirtyeight')\n",
    "#     _, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "#     # Modern color palette\n",
    "#     colors = ['#1f77b4', '#ff7f0e', \"#25a325\", \"#d61e1e\", '#9467bd']\n",
    "    \n",
    "#     # Extract the timestep and boundaries\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "    \n",
    "#     # Extract and plot x & y coordinates with better styling\n",
    "#     x, y = df['global_step'], df['episodic_return']\n",
    "#     ax.plot(x, y, linewidth=2.5, alpha=0.8, color=colors[0], zorder=3)\n",
    "    \n",
    "#     # Add vertical lines with modern styling\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         ax.axvline(x=task_boundaries_steps[indx], color=colors[indx], linestyle='dashed', \n",
    "#                   linewidth=2, alpha=0.7, zorder=2, label=f'{sequence[indx-1]}→{task}')\n",
    "    \n",
    "#     # Improved styling\n",
    "#     ax.set_xlabel('Total Timesteps', fontsize=14, fontweight='bold')\n",
    "#     ax.set_ylabel('Episodic Return', fontsize=14, fontweight='bold')\n",
    "#     ax.set_title('Training Reward - Best HPO Trial', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "#     # Better grid and background\n",
    "#     ax.grid(True, alpha=0.75, linestyle='dashed', linewidth=0.5)\n",
    "#     ax.set_facecolor('#fafafa')\n",
    "    \n",
    "#     # Modern legend\n",
    "#     legend = ax.legend(loc='lower right', frameon=True, fancybox=True, shadow=True, fontsize=12)\n",
    "#     legend.get_frame().set_facecolor('white')\n",
    "#     legend.get_frame().set_alpha(0.9)\n",
    "    \n",
    "#     # Clean spines\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['left'].set_linewidth(1.5)\n",
    "#     ax.spines['bottom'].set_linewidth(1.5)\n",
    "    \n",
    "#     # Set proper margins\n",
    "#     ax.margins(0)\n",
    "#     ax.set_ylim(0, 1)\n",
    "#     # Better tick labels\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "#     plt.close()\n",
    "\n",
    "# plot_reward(path, list(sequence.keys()), './rewards.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9d626760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_training_loss(path, sequence, save_path='./loss'):\n",
    "\n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'updates.csv' file\n",
    "#     df = pd.read_csv(f'{path}/updates.csv')\n",
    "    \n",
    "#     # Extract the first global_step value at the start of every task -> Very messy, but good enough for now\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "\n",
    "#     # Extract and plot x & y coordinates\n",
    "#     x, y = df['global_step'], df['policy_loss']\n",
    "#     plt.plot(x, y)\n",
    "#     plt.xlabel('Total Timesteps')\n",
    "#     plt.ylabel('Policy Loss')\n",
    "    \n",
    "#     # Add vertical lines across the plot to differentiate task training\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         plt.axvline(x=task_boundaries_steps[indx], color=colours[indx-1], linestyle='dashed', alpha=0.4, label=f'{sequence[indx-1]}→{task}')\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.plot()\n",
    "#     plt.savefig(save_path)\n",
    "#     plt.close()\n",
    "\n",
    "# # plot_training_loss(path, list(sequence.keys()), './loss.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f67fe968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_loss_curve(path, sequence, save_path='./rewards.svg'):\n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'updates.csv' file\n",
    "#     df = pd.read_csv(f'{path}/updates.csv')\n",
    "    \n",
    "#     # Set up modern styling\n",
    "#     plt.style.use('fivethirtyeight')\n",
    "#     _, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "#     # Modern color palette\n",
    "#     colors = ['#1f77b4', '#ff7f0e', \"#25a325\", \"#d61e1e\", '#9467bd']\n",
    "    \n",
    "#     # Extract the timestep and boundaries\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "    \n",
    "#     # Extract and plot x & y coordinates with better styling\n",
    "#     x, y = df['global_step'], df['policy_loss']\n",
    "#     ax.plot(x, y, linewidth=2.5, alpha=0.8, color=colors[0], zorder=3)\n",
    "    \n",
    "#     # Add vertical lines with modern styling\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         ax.axvline(x=task_boundaries_steps[indx], color=colors[indx], linestyle='dashed', \n",
    "#                   linewidth=2, alpha=0.7, zorder=2, label=f'{sequence[indx-1]}→{task}')\n",
    "    \n",
    "#     # Improved styling\n",
    "#     ax.set_xlabel('Total Timesteps', fontsize=14, fontweight='bold')\n",
    "#     ax.set_ylabel('Policy Loss', fontsize=14, fontweight='bold')\n",
    "#     ax.set_title('Training Loss - Best HPO Trial', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "#     # Better grid and background\n",
    "#     ax.grid(True, alpha=0.75, linestyle='dashed', linewidth=0.5)\n",
    "#     ax.set_facecolor('#fafafa')\n",
    "    \n",
    "#     # Modern legend\n",
    "#     legend = ax.legend(loc='lower right', frameon=True, fancybox=True, shadow=True, fontsize=12)\n",
    "#     legend.get_frame().set_facecolor('white')\n",
    "#     legend.get_frame().set_alpha(0.9)\n",
    "    \n",
    "#     # Clean spines\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['left'].set_linewidth(1.5)\n",
    "#     ax.spines['bottom'].set_linewidth(1.5)\n",
    "    \n",
    "#     # Set proper margins\n",
    "#     # ax.margins(0)\n",
    "#     # ax.set_ylim(0, 1)\n",
    "#     # Better tick labels\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "#     plt.close()\n",
    "\n",
    "# plot_loss_curve(path, list(sequence.keys()), './loss.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
