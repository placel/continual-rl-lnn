{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf3cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a009255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['red', 'green', 'blue', 'orange', 'purple']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351dd9ff",
   "metadata": {},
   "source": [
    "#### HPO Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09fd3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all best_trial trials into array\n",
    "hpo_sequence = {\n",
    "        'MiniGrid-Empty-5x5-v0': 5,\n",
    "        'MiniGrid-DoorKey-5x5-v0': 8, \n",
    "        'MiniGrid-Unlock-v0': 18\n",
    "    }  \n",
    "\n",
    "# best_trial = 12\n",
    "# best_trial = 4\n",
    "best_trial = 29\n",
    "# study_name = 'shared_cfc_hpo_3_final'\n",
    "# study_name = 'lstm_ewc'\n",
    "study_name = 'mlp_ewc_final'\n",
    "hpo_path = fr\"C:\\Users\\Logan\\Documents\\School\\Wales\\MSc\\continual-rl-lnn\\src\\continual\\minigrid\\HPO\\{study_name}\\models\"\n",
    "\n",
    "# seeds = [1001, 2002, 3003] # HPO Seeds\n",
    "seeds = [10001, 20002, 30003] # EWC Seeds\n",
    "perf_mats = [np.load(f'{hpo_path}\\hpo_trial_{best_trial}_{seeds[i]}\\performance_matrix.npy') for i in range(len(seeds))]\n",
    "perf_std_mats = [np.load(f'{hpo_path}\\hpo_trial_{best_trial}_{seeds[i]}\\performance_std_matrix.npy') for i in range(len(seeds))]\n",
    "\n",
    "optuna_mean_perf_mat = np.mean(perf_mats, axis=0) # Per-task average across all perf_matrices\n",
    "optuna_mean_perf_std_mat = np.mean(perf_std_mats, axis=0) # Per-task average across all perf_std_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c6a0c",
   "metadata": {},
   "source": [
    "#### Experiments Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1702dfbf",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "exp_sequence = {\n",
    "        'MiniGrid-Empty-5x5-v0': 5,\n",
    "        'MiniGrid-DoorKey-5x5-v0': 8, \n",
    "        'MiniGrid-Unlock-v0': 18\n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b3dc65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'CfC_A&C'\n",
    "# model_type = 'CfC_Actor'\n",
    "# model_type = 'CfC_Critic'\n",
    "# model_type = 'LSTM'\n",
    "model_type = 'MLP'\n",
    "# experiment_name = 'phase_one_final_200'\n",
    "# experiment_name = 'phase_two'\n",
    "# experiment_name = 'phase_three'\n",
    "experiment_name = 'clear_sweep'\n",
    "exp_path = fr\"C:\\Users\\Logan\\Documents\\School\\Wales\\MSc\\continual-rl-lnn\\src\\continual\\minigrid\\experiments\\{experiment_name}\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86009c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/Logan/Documents/School/Wales/MSc/continual-rl-lnn/src/continual/minigrid/experiments/clear_sweep/models/MLP_1756928858'),\n",
       " WindowsPath('C:/Users/Logan/Documents/School/Wales/MSc/continual-rl-lnn/src/continual/minigrid/experiments/clear_sweep/models/MLP_1756929233'),\n",
       " WindowsPath('C:/Users/Logan/Documents/School/Wales/MSc/continual-rl-lnn/src/continual/minigrid/experiments/clear_sweep/models/MLP_1756929610'),\n",
       " WindowsPath('C:/Users/Logan/Documents/School/Wales/MSc/continual-rl-lnn/src/continual/minigrid/experiments/clear_sweep/models/MLP_1756929987'),\n",
       " WindowsPath('C:/Users/Logan/Documents/School/Wales/MSc/continual-rl-lnn/src/continual/minigrid/experiments/clear_sweep/models/MLP_1756930359'),\n",
       " WindowsPath('C:/Users/Logan/Documents/School/Wales/MSc/continual-rl-lnn/src/continual/minigrid/experiments/clear_sweep/models/MLP_1756930735')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_model_dirs(base_path, model_type):\n",
    "    base = Path(base_path)\n",
    "    return [p for p in base.iterdir() if p.is_dir() and model_type in p.name]\n",
    "\n",
    "folders = find_model_dirs(exp_path, model_type)\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6658f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_mats = [np.load(f'{exp_path}\\{f.name}\\performance_matrix.npy') for f in folders]\n",
    "perf_std_mats = [np.load(f'{exp_path}\\{f.name}\\performance_std_matrix.npy') for f in folders]\n",
    "\n",
    "mean_perf_mat = np.mean(perf_mats, axis=0) # Per-task average across all perf_matrices\n",
    "mean_perf_std_mat = np.mean(perf_std_mats, axis=0) # Per-task average across all perf_std_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "316249af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95500004, 0.        , 0.        ],\n",
       "       [0.95500004, 0.96415995, 0.        ],\n",
       "       [0.95500004, 0.78259108, 0.86843749]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_perf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f900cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# def find_model_dirs(base_path, model_type):\n",
    "#     base = Path(base_path)\n",
    "#     return [p for p in base.iterdir() if p.is_dir() and model_type in p.name]\n",
    "\n",
    "# # folders = [find_model_dirs(p, model_type) for p in exp_paths]\n",
    "\n",
    "# # Load all model paths to every experiment and model type. Results are an array of each experiment, with an array of all model paths\n",
    "# folders = {}\n",
    "# for i, e in enumerate(exp_paths):\n",
    "#     for m in model_types:\n",
    "#         folders[f'{experiment_names[i]}_{m}'] = (find_model_dirs(e, m))\n",
    "\n",
    "# folders['phase_one_final_200_CfC_A&C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce5b0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def avg_curve_per_task(paths, nbins=200):\n",
    "#     import pandas as pd, numpy as np\n",
    "#     dfs = [pd.read_csv(p/'episodes.csv', usecols=['global_step','task_index','episodic_return']) for p in paths]\n",
    "#     tasks = sorted(set().union(*[set(df.task_index.unique()) for df in dfs]))\n",
    "#     X, Y = [], []\n",
    "#     for t in tasks:\n",
    "#         # interpolate each seed onto 0..1 progress within the task\n",
    "#         seeds = []\n",
    "#         for df in dfs:\n",
    "#             d = df[df.task_index==t].sort_values('global_step')\n",
    "#             if len(d)<2: continue\n",
    "#             x = d.global_step.values\n",
    "#             p = (x - x.min())/(x.max()-x.min())\n",
    "#             y = d.episodic_return.values\n",
    "#             grid = np.linspace(0,1,nbins)\n",
    "#             yi = np.interp(grid, p, y)\n",
    "#             seeds.append(yi)\n",
    "#         if not seeds: continue\n",
    "#         ymean = np.mean(np.vstack(seeds), axis=0)\n",
    "#         X.append(t + grid)           # task offset\n",
    "#         Y.append(ymean)\n",
    "#     if not X: return None, None\n",
    "#     return np.concatenate(X), np.concatenate(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "92dd2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def extract_task_names(sequence):\n",
    "#     return [tasks.split('-')[1] for tasks in sequence]\n",
    "\n",
    "# def avg_curve_per_task(paths, nbins=200):\n",
    "#     \"\"\"Returns x = task_index + progress, y = mean episodic_return across seeds.\"\"\"\n",
    "#     dfs = [pd.read_csv(p/'episodes.csv', usecols=['global_step','task_index','episodic_return']) for p in paths]\n",
    "#     tasks = sorted(set().union(*[set(df.task_index.unique()) for df in dfs]))\n",
    "#     X, Y = [], []\n",
    "#     for t in tasks:\n",
    "#         seeds = []\n",
    "#         for df in dfs:\n",
    "#             d = df[df.task_index==t].sort_values('global_step')\n",
    "#             if len(d) < 2:\n",
    "#                 continue\n",
    "#             x = d.global_step.to_numpy()\n",
    "#             p = (x - x.min()) / (x.max() - x.min())\n",
    "#             y = d.episodic_return.to_numpy()\n",
    "#             grid = np.linspace(0, 1, nbins)\n",
    "#             yi = np.interp(grid, p, y)\n",
    "#             seeds.append(yi)\n",
    "#         if not seeds:\n",
    "#             continue\n",
    "#         ymean = np.mean(np.vstack(seeds), axis=0)\n",
    "#         X.append(t + grid)    # task offset on x-axis\n",
    "#         Y.append(ymean)\n",
    "#     if not X:\n",
    "#         return None, None, []\n",
    "#     return np.concatenate(X), np.concatenate(Y), tasks\n",
    "\n",
    "# def plot_avg_reward_per_task(paths, sequence, save_path='./rewards_avg.svg', nbins=200, title='Training Reward â€“ Mean of 5 seeds'):\n",
    "#     # style to match your first function\n",
    "#     plt.style.use('fivethirtyeight')\n",
    "#     fig, ax = plt.subplots(figsize=(12, 8))\n",
    "#     colors = ['#1f77b4', '#ff7f0e', \"#25a325\", \"#d61e1e\", '#9467bd']\n",
    "\n",
    "#     # optional: map pretty task names\n",
    "#     seq_names = extract_task_names(sequence)  # keep your helper\n",
    "\n",
    "#     x, y, tasks = avg_curve_per_task(paths, nbins=nbins)\n",
    "#     if x is None:\n",
    "#         raise ValueError(\"No data available to plot.\")\n",
    "\n",
    "#     # main curve\n",
    "#     ax.plot(x, y, linewidth=2.5, alpha=0.8, color=colors[0], zorder=3)\n",
    "\n",
    "#     # vertical boundaries between tasks at integer indices\n",
    "#     # tasks assumed sorted like [0,1,2,...]; boundaries at 1,2,...,len(tasks)-1\n",
    "#     for i in range(1, len(tasks)):\n",
    "#         ax.axvline(x=i, color=colors[i % len(colors)], linestyle='solid',\n",
    "#                    linewidth=3, alpha=1.0, zorder=10,\n",
    "#                    label=f'{seq_names[i-1]}â†’{seq_names[i]}')\n",
    "\n",
    "#     # labels and styling\n",
    "#     ax.set_xlabel('Task Index + Normalized Progress', fontsize=14, fontweight='bold')\n",
    "#     ax.set_ylabel('Episodic Return', fontsize=14, fontweight='bold')\n",
    "#     ax.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "#     ax.grid(True, alpha=0.75, linestyle='dashed', linewidth=0.5)\n",
    "#     ax.set_facecolor('#fafafa')\n",
    "#     ax.margins(0)\n",
    "#     ax.set_ylim(0, 1)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "#     legend = ax.legend(loc='lower right', frameon=True, fancybox=True, shadow=True, fontsize=12)\n",
    "#     legend.get_frame().set_facecolor('white')\n",
    "#     legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['left'].set_linewidth(1.5)\n",
    "#     ax.spines['bottom'].set_linewidth(1.5)\n",
    "#     # ax.xaxis.set_visible(False)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f3791dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_segmented(ax, x, y, tasks, color, label, nbins, lw=2.0, alpha=0.75):\n",
    "#     i = 0\n",
    "#     for t_idx, _ in enumerate(tasks):\n",
    "#         xs = x[i:i+nbins]\n",
    "#         ys = y[i:i+nbins]\n",
    "#         ax.plot(xs, ys, color=color, linewidth=lw, alpha=alpha, \n",
    "#                 label=label if t_idx == 0 else None)\n",
    "#         i += nbins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "062ffc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "\n",
    "# DISPLAY = {\n",
    "#     'CfC_A&C': 'CfC A&C',\n",
    "#     'CfC_Actor': 'CfC Actor',\n",
    "#     'CfC_Critic': 'CfC Critic',\n",
    "#     'LSTM': 'LSTM',\n",
    "#     'MLP': 'MLP',\n",
    "# }\n",
    "\n",
    "# from scipy.signal import savgol_filter\n",
    "\n",
    "# # def get_gnbu_colors(n, vmin=0.3, vmax=0.1):\n",
    "# #     cmap = cm.get_cmap(\"GnBu\")\n",
    "# #     return [cmap(v) for v in np.linspace(vmin, vmax, n)]\n",
    "\n",
    "# def smooth_curve(y, window=11, poly=3):\n",
    "#     # window must be odd and <= len(y)\n",
    "#     if len(y) < window:\n",
    "#         return y\n",
    "#     return savgol_filter(y, window_length=window, polyorder=poly)\n",
    "\n",
    "# def extract_task_names(sequence):\n",
    "#     return [s.split('-')[1] for s in sequence]\n",
    "\n",
    "# def avg_curve_per_task(paths, nbins=200):\n",
    "#     dfs = [pd.read_csv(p/'episodes.csv', usecols=['global_step','task_index','episodic_return'])\n",
    "#            for p in paths if (p/'episodes.csv').exists()]\n",
    "#     if not dfs:\n",
    "#         return None, None, []\n",
    "#     tasks = sorted(set().union(*[set(df.task_index.unique()) for df in dfs]))\n",
    "#     X, Y = [], []\n",
    "#     for t in tasks:\n",
    "#         seeds = []\n",
    "#         for df in dfs:\n",
    "#             d = df[df.task_index == t].sort_values('global_step')\n",
    "#             if len(d) < 2:\n",
    "#                 continue\n",
    "#             x = d.global_step.to_numpy()\n",
    "#             p = (x - x.min()) / (x.max() - x.min())\n",
    "#             y = d.episodic_return.to_numpy()\n",
    "#             grid = np.linspace(0, 1, nbins)\n",
    "#             yi = np.interp(grid, p, y)\n",
    "#             seeds.append(yi)\n",
    "#         if seeds:\n",
    "#             ymean = np.mean(np.vstack(seeds), axis=0)\n",
    "#             X.append(t + grid)\n",
    "#             Y.append(ymean)\n",
    "#     if not X:\n",
    "#         return None, None, []\n",
    "#     return np.concatenate(X), np.concatenate(Y), tasks\n",
    "\n",
    "# def plot_all_models_one_fig(folders, exp_name, model_types, sequence,\n",
    "#                             save_path='./rewards_avg_all.svg', nbins=200,\n",
    "#                             title='Phase 3 Learning Curves',\n",
    "#                             smooth=True, smooth_window=11, smooth_poly=3):\n",
    "#     plt.style.use('fivethirtyeight')\n",
    "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "#     colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "#     colors_lines = sns.color_palette(\"muted\", len(model_types))\n",
    "\n",
    "#     seq_names = extract_task_names(sequence)\n",
    "#     tasks_ref = None\n",
    "\n",
    "#     plotted = 0\n",
    "#     for i, m in enumerate(model_types):\n",
    "#         key = f'{exp_name}_{m}'\n",
    "#         paths = folders.get(key, [])\n",
    "#         if not paths:\n",
    "#             continue\n",
    "#         x, y, tasks = avg_curve_per_task(paths, nbins=nbins)\n",
    "#         if x is None:\n",
    "#             continue\n",
    "\n",
    "#         if smooth:\n",
    "#             y = smooth_curve(y, window=smooth_window, poly=smooth_poly)\n",
    "\n",
    "#         ax.plot(x, y, linewidth=1.5, alpha=0.7, color=colors_lines[i],\n",
    "#                 zorder=3, label=DISPLAY.get(m, m))\n",
    "#         plotted += 1\n",
    "#         if tasks_ref is None:\n",
    "#             tasks_ref = tasks  # use first successful model to place boundaries\n",
    "\n",
    "#     # task boundaries and labels\n",
    "#     if tasks_ref:\n",
    "#         # Place ticks at task boundaries + halfway into each task\n",
    "#         tick_positions = [i + 0.5 for i in range(len(tasks_ref))]\n",
    "#         ax.set_xticks(tick_positions)\n",
    "#         ax.set_xticklabels(seq_names, fontsize=12, rotation=30, ha='right')\n",
    "\n",
    "#     ax.set_ylabel('Smoothed Episodic Return', fontsize=14, fontweight='bold')\n",
    "#     ax.set_title(f'{title}', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "#     ax.grid(True, alpha=0.75, linestyle='dashed', linewidth=0.5)\n",
    "#     ax.set_facecolor('#fafafa')\n",
    "#     ax.margins(0)\n",
    "#     ax.set_ylim(0, 1)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['left'].set_linewidth(1.5)\n",
    "#     ax.spines['bottom'].set_linewidth(1.5)\n",
    "\n",
    "#     leg = ax.legend(loc='lower right', frameon=True, fancybox=True, shadow=True, fontsize=11)\n",
    "#     leg.get_frame().set_facecolor('white')\n",
    "#     leg.get_frame().set_alpha(0.9)\n",
    "\n",
    "#     Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "#     plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "391c2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all_models_one_fig(\n",
    "#     folders=folders,\n",
    "#     exp_name='phase_one_final_200',\n",
    "#     model_types=model_types,\n",
    "#     sequence=exp_sequence,\n",
    "#     save_path='./plots/phase_one_final_all_models.svg',\n",
    "#     nbins=200,\n",
    "#     title='Phase 1 Learning Curves'\n",
    "# )\n",
    "\n",
    "# plot_all_models_one_fig(\n",
    "#     folders=folders,\n",
    "#     exp_name='phase_two',\n",
    "#     model_types=model_types,\n",
    "#     sequence=exp_sequence,\n",
    "#     save_path='./plots/phase_two_all_models.svg',\n",
    "#     nbins=200,\n",
    "#     title='Phase 2 Learning Curves'\n",
    "# )\n",
    "\n",
    "# plot_all_models_one_fig(\n",
    "#     folders=folders,\n",
    "#     exp_name='phase_three',\n",
    "#     model_types=model_types,\n",
    "#     sequence=exp_sequence,\n",
    "#     save_path='./plots/phase_three_all_models.svg',\n",
    "#     nbins=200,\n",
    "#     title='Phase 3 Learning Curves'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "065da193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = folders['phase_one_final_LSTM']  # list[Path]\n",
    "# plot_avg_reward_per_task(paths, exp_sequence, save_path='./lstm_rewards_avg.svg', nbins=300,\n",
    "#                          title='LSTM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c9270dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # per-task stitched\n",
    "# # x2,y2 = avg_curve_per_task(folders['phase_one_final_CfC_Critic'])\n",
    "# x2,y2 = avg_curve_per_task(folders['phase_one_final_LSTM'])\n",
    "# plt.figure(); plt.plot(x2,y2); plt.xlabel('Task index + progress'); plt.ylabel('Episodic return'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "26d7618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_rewards(dirs):\n",
    "#     vals = []\n",
    "#     cols = ['global_step', 'task_index', 'episodic_return']\n",
    "#     for d in dirs:\n",
    "#         df = pd.read_csv(d / 'episodes.csv')\n",
    "#         temp = np.array(df[cols].values)\n",
    "#         vals.append(df[cols].values)\n",
    "\n",
    "#     vals = np.array(vals).mean()\n",
    "#     return vals\n",
    "\n",
    "# res = average_rewards(folders['phase_one_final_CfC_A&C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b40a78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53aed8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_mats = [np.load(f'{exp_path}\\{f.name}\\performance_matrix.npy') for f in folders]\n",
    "# perf_std_mats = [np.load(f'{exp_path}\\{f.name}\\performance_std_matrix.npy') for f in folders]\n",
    "\n",
    "# mean_perf_mat = np.mean(perf_mats, axis=0) # Per-task average across all perf_matrices\n",
    "# mean_perf_std_mat = np.mean(perf_std_mats, axis=0) # Per-task average across all perf_std_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e88e2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_perf_mat\n",
    "# # mean_perf_std_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e93ff221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perf_matrix(mean_perf_mat, mean_perf_std_mat, sequence=None, save_path='./performance_matrix', std=False):\n",
    "    # labels\n",
    "    labels = []\n",
    "    for e in sequence:\n",
    "        e = e.split('-')\n",
    "        labels.append('-'.join(e[1:2]) if len(e) >= 4 else e[1])\n",
    "\n",
    "    if std:\n",
    "        annot = np.empty_like(mean_perf_mat, dtype=object)\n",
    "        for i in range(mean_perf_mat.shape[0]):\n",
    "            for j in range(mean_perf_mat.shape[1]):\n",
    "                annot[i, j] = f\"{mean_perf_mat[i, j]:.2f}\\nÂ±{mean_perf_std_mat[i, j]:.2f}\"\n",
    "\n",
    "    # figure + equal cells\n",
    "    fig, ax = plt.subplots(figsize=(6, 5.5), constrained_layout=True)\n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    if std:\n",
    "        sns.heatmap(mean_perf_mat, annot=annot, fmt='', cmap='GnBu',\n",
    "                    xticklabels=labels, yticklabels=labels, cbar=False, square=True, ax=ax)\n",
    "    else:\n",
    "        sns.heatmap(mean_perf_mat, annot=True, fmt='.2f', cmap='GnBu',\n",
    "                    xticklabels=labels, yticklabels=labels, cbar=False, square=True, ax=ax)\n",
    "\n",
    "    if 'LSTM' in model_type: plt.title('LSTM')\n",
    "    if 'MLP' in model_type:  plt.title('MLP')\n",
    "    if 'CfC_A&C' in model_type:  plt.title('CfC A&C')\n",
    "    if 'CfC_Actor' in model_type:  plt.title('CfC Actor')\n",
    "    if 'CfC_Critic' in model_type:  plt.title('CfC Critic')\n",
    "    # if 'lstm' in study_name: plt.title('LSTM')\n",
    "    # if 'mlp' in study_name:  plt.title('MLP')\n",
    "    # if 'cfc' in study_name:  plt.title('CfC A&C')\n",
    "\n",
    "    if std: save_path = f'{save_path}_std'\n",
    "    out_path = Path(f\"{save_path}.svg\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# plot_perf_matrix(optuna_mean_perf_mat, optuna_mean_perf_std_mat, hpo_sequence, save_path=f'optuna_{study_name}/mean_performance')\n",
    "# plot_perf_matrix(optuna_mean_perf_mat, optuna_mean_perf_std_mat, hpo_sequence, save_path=f'optuna_{study_name}/mean_performance', std=True)\n",
    "plot_perf_matrix(mean_perf_mat, mean_perf_std_mat, exp_sequence, save_path=f'{model_type}_{experiment_name}/mean_performance')\n",
    "plot_perf_matrix(mean_perf_mat, mean_perf_std_mat, exp_sequence, save_path=f'{model_type}_{experiment_name}/mean_performance', std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42276eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_task_names(sequence):\n",
    "#     return [tasks.split('-')[1] for tasks in sequence]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "236969f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_reward(path, sequence, save_path='./loss'):\n",
    "\n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'updates.csv' file\n",
    "#     df = pd.read_csv(f'{path}/episodes.csv')\n",
    "    \n",
    "#     # Extract the timestep\n",
    "#     training_step = df['global_step'][0] # Extract the first logged global_step\n",
    "\n",
    "#     # Extract the first global_step value at the start of every task -> Very messy, but good enough for now\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "\n",
    "#     print(training_step)\n",
    "#     print(task_boundaries_steps)\n",
    "\n",
    "#     # Extract and plot x & y coordinates\n",
    "#     x, y = df['global_step'], df['episodic_return']\n",
    "#     plt.plot(x, y)\n",
    "#     plt.xlabel('Total Timesteps')\n",
    "#     plt.ylabel('Reward')\n",
    "    \n",
    "#     # Add vertical lines across the plot to differentiate task training\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         plt.axvline(x=task_boundaries_steps[indx], color=colours[indx-1], linestyle='dashed', alpha=0.4, label=f'{sequence[indx-1]}â†’{task}')\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.plot()\n",
    "#     plt.savefig(save_path)\n",
    "#     plt.close()\n",
    "\n",
    "# # plot_reward(path, list(sequence.keys()), './rewards.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2eaeae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_reward(path, sequence, save_path='./rewards.svg'):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "#     import pandas as pd\n",
    "#     from scipy.signal import savgol_filter\n",
    "    \n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'episodes.csv' file\n",
    "#     df = pd.read_csv(f'{path}/episodes.csv')\n",
    "    \n",
    "#     # Set up modern styling\n",
    "#     plt.style.use('fivethirtyeight')\n",
    "#     _, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "#     # Modern color palette\n",
    "#     colors = ['#1f77b4', '#ff7f0e', \"#25a325\", \"#d61e1e\", '#9467bd']\n",
    "    \n",
    "#     # Extract the timestep and boundaries\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "    \n",
    "#     # Extract and plot x & y coordinates with better styling\n",
    "#     x, y = df['global_step'], df['episodic_return']\n",
    "#     ax.plot(x, y, linewidth=2.5, alpha=0.8, color=colors[0], zorder=3)\n",
    "    \n",
    "#     # Add vertical lines with modern styling\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         ax.axvline(x=task_boundaries_steps[indx], color=colors[indx], linestyle='dashed', \n",
    "#                   linewidth=2, alpha=0.7, zorder=2, label=f'{sequence[indx-1]}â†’{task}')\n",
    "    \n",
    "#     # Improved styling\n",
    "#     ax.set_xlabel('Total Timesteps', fontsize=14, fontweight='bold')\n",
    "#     ax.set_ylabel('Episodic Return', fontsize=14, fontweight='bold')\n",
    "#     ax.set_title('Training Reward - Best HPO Trial', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "#     # Better grid and background\n",
    "#     ax.grid(True, alpha=0.75, linestyle='dashed', linewidth=0.5)\n",
    "#     ax.set_facecolor('#fafafa')\n",
    "    \n",
    "#     # Modern legend\n",
    "#     legend = ax.legend(loc='lower right', frameon=True, fancybox=True, shadow=True, fontsize=12)\n",
    "#     legend.get_frame().set_facecolor('white')\n",
    "#     legend.get_frame().set_alpha(0.9)\n",
    "    \n",
    "#     # Clean spines\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['left'].set_linewidth(1.5)\n",
    "#     ax.spines['bottom'].set_linewidth(1.5)\n",
    "    \n",
    "#     # Set proper margins\n",
    "#     ax.margins(0)\n",
    "#     ax.set_ylim(0, 1)\n",
    "#     # Better tick labels\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "#     plt.close()\n",
    "\n",
    "# plot_reward(path, list(sequence.keys()), './rewards.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3828f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d626760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_training_loss(path, sequence, save_path='./loss'):\n",
    "\n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'updates.csv' file\n",
    "#     df = pd.read_csv(f'{path}/updates.csv')\n",
    "    \n",
    "#     # Extract the first global_step value at the start of every task -> Very messy, but good enough for now\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "\n",
    "#     # Extract and plot x & y coordinates\n",
    "#     x, y = df['global_step'], df['policy_loss']\n",
    "#     plt.plot(x, y)\n",
    "#     plt.xlabel('Total Timesteps')\n",
    "#     plt.ylabel('Policy Loss')\n",
    "    \n",
    "#     # Add vertical lines across the plot to differentiate task training\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         plt.axvline(x=task_boundaries_steps[indx], color=colours[indx-1], linestyle='dashed', alpha=0.4, label=f'{sequence[indx-1]}â†’{task}')\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.plot()\n",
    "#     plt.savefig(save_path)\n",
    "#     plt.close()\n",
    "\n",
    "# # plot_training_loss(path, list(sequence.keys()), './loss.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f67fe968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_loss_curve(path, sequence, save_path='./rewards.svg'):\n",
    "#     sequence = extract_task_names(sequence)\n",
    "#     # Load the models associated 'updates.csv' file\n",
    "#     df = pd.read_csv(f'{path}/updates.csv')\n",
    "    \n",
    "#     # Set up modern styling\n",
    "#     plt.style.use('fivethirtyeight')\n",
    "#     _, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "#     # Modern color palette\n",
    "#     colors = ['#1f77b4', '#ff7f0e', \"#25a325\", \"#d61e1e\", '#9467bd']\n",
    "    \n",
    "#     # Extract the timestep and boundaries\n",
    "#     task_boundaries_steps = [list(df[df['task_index'] == i]['global_step'])[0] for i in range(len(sequence))]\n",
    "    \n",
    "#     # Extract and plot x & y coordinates with better styling\n",
    "#     x, y = df['global_step'], df['policy_loss']\n",
    "#     ax.plot(x, y, linewidth=2.5, alpha=0.8, color=colors[0], zorder=3)\n",
    "    \n",
    "#     # Add vertical lines with modern styling\n",
    "#     for indx, task in enumerate(sequence):\n",
    "#         if indx == 0: continue\n",
    "#         ax.axvline(x=task_boundaries_steps[indx], color=colors[indx], linestyle='dashed', \n",
    "#                   linewidth=2, alpha=0.7, zorder=2, label=f'{sequence[indx-1]}â†’{task}')\n",
    "    \n",
    "#     # Improved styling\n",
    "#     ax.set_xlabel('Total Timesteps', fontsize=14, fontweight='bold')\n",
    "#     ax.set_ylabel('Policy Loss', fontsize=14, fontweight='bold')\n",
    "#     ax.set_title('Training Loss - Best HPO Trial', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "#     # Better grid and background\n",
    "#     ax.grid(True, alpha=0.75, linestyle='dashed', linewidth=0.5)\n",
    "#     ax.set_facecolor('#fafafa')\n",
    "    \n",
    "#     # Modern legend\n",
    "#     legend = ax.legend(loc='lower right', frameon=True, fancybox=True, shadow=True, fontsize=12)\n",
    "#     legend.get_frame().set_facecolor('white')\n",
    "#     legend.get_frame().set_alpha(0.9)\n",
    "    \n",
    "#     # Clean spines\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['left'].set_linewidth(1.5)\n",
    "#     ax.spines['bottom'].set_linewidth(1.5)\n",
    "    \n",
    "#     # Set proper margins\n",
    "#     # ax.margins(0)\n",
    "#     # ax.set_ylim(0, 1)\n",
    "#     # Better tick labels\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "#     plt.close()\n",
    "\n",
    "# plot_loss_curve(path, list(sequence.keys()), './loss.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
